{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khanhtran2000/OCR-Dev/blob/master/MNIST_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zX4Kg8DUTKWO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rEHcB3kqyHZ6",
        "outputId": "8afd4466-42f7-4ade-eb5a-df84b45b2210",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras import datasets, models\n",
        "from tensorflow.keras.layers import Reshape\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "'''\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('accuracy')>0.99):\n",
        "      print(\"\\nReached 99% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "'''\n",
        "\n",
        "# Decrease learning rate each epoch\n",
        "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x)\n",
        "\n",
        "mnist = datasets.mnist\n",
        "\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "#callbacks = myCallback()\n",
        "\n",
        "model = models.Sequential()\n",
        "\n",
        "# Reshape the shape of the input or it will raise a ValueError. \n",
        "# CNN takes input shape of 4 dimensions (batchsize, width, height, depth)\n",
        "model.add(Reshape((28, 28, 1)))\n",
        "\n",
        "# First Conv layer C1 with 5x5 filters was replaced with two stacked Conv \n",
        "# layers with 3x3 filters.\n",
        "model.add(Conv2D(32, kernel_size=3, activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(BatchNormalization()) # BatchNormalization added\n",
        "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
        "model.add(BatchNormalization()) \n",
        "# Pooling layer S2 was replaced with a Conv layer with stride 2\n",
        "model.add(Conv2D(32, kernel_size=5, strides=2, padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4)) # Dropout added\n",
        "\n",
        "# Same changes were made for Conv layer C3 and Pooling layer S4\n",
        "model.add(Conv2D(64, kernel_size=3, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, kernel_size=3, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, kernel_size=5, strides=2, padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "# Conv layer C6 was kept the same? \n",
        "model.add(Conv2D(128, kernel_size=4, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(10, activation=tf.nn.softmax))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=20, callbacks=[annealer])\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 269s 144ms/step - loss: 0.1822 - accuracy: 0.9453 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 271s 144ms/step - loss: 0.0694 - accuracy: 0.9792 - lr: 9.5000e-04\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 261s 139ms/step - loss: 0.0549 - accuracy: 0.9837 - lr: 9.0250e-04\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 267s 142ms/step - loss: 0.0468 - accuracy: 0.9860 - lr: 8.5737e-04\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 260s 138ms/step - loss: 0.0385 - accuracy: 0.9888 - lr: 8.1451e-04\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 264s 141ms/step - loss: 0.0337 - accuracy: 0.9895 - lr: 7.7378e-04\n",
            "Epoch 7/20\n",
            "1875/1875 [==============================] - 264s 141ms/step - loss: 0.0309 - accuracy: 0.9906 - lr: 7.3509e-04\n",
            "Epoch 8/20\n",
            "1875/1875 [==============================] - 254s 135ms/step - loss: 0.0260 - accuracy: 0.9922 - lr: 6.9834e-04\n",
            "Epoch 9/20\n",
            "1875/1875 [==============================] - 262s 140ms/step - loss: 0.0227 - accuracy: 0.9934 - lr: 6.6342e-04\n",
            "Epoch 10/20\n",
            "1875/1875 [==============================] - 262s 140ms/step - loss: 0.0218 - accuracy: 0.9935 - lr: 6.3025e-04\n",
            "Epoch 11/20\n",
            "1875/1875 [==============================] - 259s 138ms/step - loss: 0.0184 - accuracy: 0.9944 - lr: 5.9874e-04\n",
            "Epoch 12/20\n",
            "1875/1875 [==============================] - 265s 141ms/step - loss: 0.0170 - accuracy: 0.9949 - lr: 5.6880e-04\n",
            "Epoch 13/20\n",
            "1875/1875 [==============================] - 261s 139ms/step - loss: 0.0158 - accuracy: 0.9948 - lr: 5.4036e-04\n",
            "Epoch 14/20\n",
            "1875/1875 [==============================] - 266s 142ms/step - loss: 0.0145 - accuracy: 0.9958 - lr: 5.1334e-04\n",
            "Epoch 15/20\n",
            "1875/1875 [==============================] - 270s 144ms/step - loss: 0.0130 - accuracy: 0.9959 - lr: 4.8767e-04\n",
            "Epoch 16/20\n",
            "1875/1875 [==============================] - 270s 144ms/step - loss: 0.0120 - accuracy: 0.9962 - lr: 4.6329e-04\n",
            "Epoch 17/20\n",
            "1875/1875 [==============================] - 271s 144ms/step - loss: 0.0106 - accuracy: 0.9967 - lr: 4.4013e-04\n",
            "Epoch 18/20\n",
            "1875/1875 [==============================] - 269s 143ms/step - loss: 0.0090 - accuracy: 0.9972 - lr: 4.1812e-04\n",
            "Epoch 19/20\n",
            "1875/1875 [==============================] - 270s 144ms/step - loss: 0.0093 - accuracy: 0.9971 - lr: 3.9721e-04\n",
            "Epoch 20/20\n",
            "1875/1875 [==============================] - 271s 144ms/step - loss: 0.0077 - accuracy: 0.9975 - lr: 3.7735e-04\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f84813d10f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6992w5jKPZgd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f427f7e2-a64f-4d0b-a67e-4028eb65f610"
      },
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.01538433413952589\n",
            "Test accuracy: 0.9965999722480774\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PZkmr_DXCPc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
